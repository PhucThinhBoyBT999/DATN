import cv2
import numpy as np
import os
import time
import requests
import threading
import mediapipe as mp
from keras_facenet import FaceNet

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Cáº¤U HÃŒNH
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

BLYNK_TOKEN = "dRetcrvdh9fU4oY6Fd88XwqpBCCXNJ_5"
BLYNK_URL = f"https://blynk.cloud/external/api/update?token={BLYNK_TOKEN}"

ESP32CAM_IN = "http://192.168.137.68:81/stream"
ESP32CAM_OUT = "http://192.168.137.86:81/stream"

VPIN_FACE_ID = "V14"
VPIN_FACE_NAME = "V15"

# Google Sheets
GOOGLE_SHEETS_URL = "https://script.google.com/macros/s/AKfycbxX3sWzaTqYUfEfOXxgaTFvpt4El9pOfIRl8uy006DgPbpS3osfx6V14zHcMRJ03ull/exec?action=getUsers"

# FaceNet config
MEDIAPIPE_CONFIDENCE = 0.7
FACENET_THRESHOLD = 0.6
COOLDOWN_SECONDS = 20
CAPTURE_DELAY = 0.3

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# KHá»I Táº O
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# MediaPipe
mp_face_detection = mp.solutions.face_detection  # type: ignore
mp_drawing = mp.solutions.drawing_utils  # type: ignore

# FaceNet
print("ğŸ”„ Äang load FaceNet model...")
facenet = FaceNet()
print("âœ… FaceNet model loaded!")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TIá»†N ÃCH
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def clear_screen():
    os.system('cls' if os.name == 'nt' else 'clear')


def print_header():
    clear_screen()
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘   NHáº¬N DIá»†N - MEDIAPIPE + FACENET            â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")


def print_menu():
    print_header()
    print("  ğŸ¯ Database: Google Sheets")
    print("\n  1.  Thu tháº­p áº£nh khuÃ´n máº·t")
    print("  2.  Huáº¥n luyá»‡n FaceNet (toÃ n bá»™)")
    print("  3.  Huáº¥n luyá»‡n FaceNet (chá»‰ ngÆ°á»i má»›i) âš¡")
    print("  4.  Báº­t Cáº¢ 2 CAMERA (IN + OUT)")
    print("  5.  Quáº£n lÃ½ ngÆ°á»i dÃ¹ng")
    print("  0.  ThoÃ¡t")
    print("\n" + "â•" * 50)


def send_face_to_blynk(face_id, name, is_check_out=False):
    """Gá»­i Face ID vÃ  tÃªn lÃªn Blynk"""
    try:
        name = str(name)
        face_id = int(face_id)

        if is_check_out:
            face_id = -abs(face_id)

        url_id = f"{BLYNK_URL}&{VPIN_FACE_ID}={face_id}"
        requests.get(url_id, timeout=1)

        url_name = f"{BLYNK_URL}&{VPIN_FACE_NAME}={name}"
        requests.get(url_name, timeout=1)

        action = "OUT" if is_check_out else "IN"
        print(f"âœ… {action}: {name} (ID {face_id})")
        return True
    except:
        return False


def load_users_from_google_sheets():
    """Load users tá»« Google Sheets"""
    try:
        print("ğŸ“¡ Load Google Sheets...")

        headers = {
            'User-Agent': 'Mozilla/5.0',
            'Accept': 'application/json',
        }

        response = requests.get(GOOGLE_SHEETS_URL, timeout=10, headers=headers, allow_redirects=True)

        if response.status_code != 200:
            return {}

        data = response.json()
        users = {}
        users_list = []

        if data.get('status') == 'success':
            users_list = data.get('users', [])
        elif data.get('success') == True:
            data_obj = data.get('data', {})
            users_list = data_obj.get('users', [])

        for user in users_list:
            user_id = int(user.get('id', 0))
            if user_id > 0:
                users[user_id] = {
                    'name': user.get('name', 'Unknown'),
                    'rfid': user.get('rfid', '')
                }

        print(f"âœ… {len(users)} ngÆ°á»i")
        return users

    except Exception as e:
        print(f"âŒ Lá»—i: {e}")
        return {}


def add_user_to_file(user_id, name, rfid):
    """Backup local"""
    if not os.path.exists("users.txt"):
        with open("users.txt", "w", encoding="utf-8") as f:
            pass
    with open("users.txt", "a", encoding="utf-8") as f:
        f.write(f"{user_id},{name},{rfid}\n")

# MEDIAPIPE DETECTION

def detect_faces(frame, detector):
    """Detect faces - MediaPipe"""
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = detector.process(rgb_frame)

    faces = []
    if results.detections:
        h, w, _ = frame.shape
        for detection in results.detections:
            bbox = detection.location_data.relative_bounding_box
            x = max(0, int(bbox.xmin * w))
            y = max(0, int(bbox.ymin * h))
            width = min(int(bbox.width * w), w - x)
            height = min(int(bbox.height * h), h - y)

            if width > 50 and height > 50:
                faces.append((x, y, width, height))

    return faces
# FACENET FUNCTIONS
def get_embedding(face_rgb):
    """TÃ­nh FaceNet embedding cho 1 face (RGB)"""
    try:
        face_resized = cv2.resize(face_rgb, (160, 160))
        embedding = facenet.embeddings([face_resized])[0]
        embedding = embedding / np.linalg.norm(embedding)
        return embedding
    except Exception as e:
        print(f"âŒ Embedding error: {e}")
        return None


def compare_embeddings(embedding1, embedding2):
    """So sÃ¡nh 2 embeddings - tráº£ vá» distance"""
    distance = np.linalg.norm(embedding1 - embedding2)
    return distance
# THU THáº¬P
def collect_faces():
    print_header()
    print("     ğŸ“¸ THU THáº¬P áº¢NH                          ")

    print("ğŸ“¡ Äang load danh sÃ¡ch tá»« Google Sheets...")
    users = load_users_from_google_sheets()

    if not users:
        print("âŒ KhÃ´ng load Ä‘Æ°á»£c Google Sheets!")
        print("ğŸ’¡ Nháº­p thá»§ cÃ´ng:")
        name = input("TÃªn: ").strip()
        rfid = input("RFID: ").strip()
        face_id = input("ID: ").strip()
    else:
        print(f"âœ… TÃ¬m tháº¥y {len(users)} ngÆ°á»i\n")
        print("ğŸ“‹ DANH SÃCH:\n")
        print(f"{'ID':<5} {'TÃªn':<25} {'RFID':<15}")
        print("-" * 50)
        for uid, info in sorted(users.items()):
            print(f"{uid:<5} {info['name']:<25} {info['rfid']:<15}")

        print("\nğŸ’¡ Nháº­p TÃŠN (pháº£i giá»‘ng Google Sheets):")
        name = input("TÃªn: ").strip()

        found_user = None
        for uid, info in users.items():
            if info['name'].lower() == name.lower():
                found_user = (uid, info)
                break

        if found_user:
            face_id, user_info = found_user
            rfid = user_info['rfid']
            print(f"âœ… TÃ¬m tháº¥y: ID={face_id}, RFID={rfid}")
        else:
            print(f"âš ï¸  KhÃ´ng tÃ¬m tháº¥y '{name}' trong Google Sheets!")
            print("ğŸ’¡ Nháº­p thÃ´ng tin má»›i:")
            rfid = input("RFID: ").strip()
            face_id = input("ID: ").strip()

    try:
        face_id = int(face_id)
    except:
        print("âŒ ID pháº£i sá»‘!")
        input()
        return

    add_user_to_file(face_id, name, rfid)

    print("\n1. Camera IN | 2. Camera OUT")
    choice = input("Chá»n: ").strip()

    cam_url = ESP32CAM_IN if choice == "1" else ESP32CAM_OUT
    cam_type = "IN" if choice == "1" else "OUT"

    folder_name = f"Mauanh/{name.replace(' ', '_')}"
    if not os.path.exists(folder_name):
        os.makedirs(folder_name)
    print(f"ğŸ“ ThÆ° má»¥c: {folder_name}")

    cap = cv2.VideoCapture(cam_url)
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)

    if not cap.isOpened():
        print(f"âŒ Camera {cam_type} lá»—i!")
        input()
        return

    detector = mp_face_detection.FaceDetection(model_selection=0,
                                               min_detection_confidence=MEDIAPIPE_CONFIDENCE)  # type: ignore

    count, max_images = 0, 100
    last_capture_time = 0

    print(f"\nğŸ“¸ Thu {max_images} áº£nh - Q thoÃ¡t")
    print(f"ğŸ’¡ ÄÆ°a máº·t vÃ o camera, Ä‘á»£i chá»¯ 'READY' mÃ u xanh!\n")

    while count < max_images:
        ret, frame = cap.read()
        if not ret:
            time.sleep(0.01)
            continue

        current_time = time.time()
        faces = detect_faces(frame, detector)

        time_since_last = current_time - last_capture_time
        can_capture = (time_since_last >= CAPTURE_DELAY) and (count > 0 or time_since_last > 1.0)

        cv2.putText(frame, f"{cam_type}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(frame, f"Saved: {count}/{max_images}", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

        if len(faces) == 0:
            status = "NO FACE"
            status_color = (0, 0, 255)
        elif can_capture:
            status = "READY"
            status_color = (0, 255, 0)
        else:
            cooldown = CAPTURE_DELAY - time_since_last
            status = f"Wait {cooldown:.1f}s"
            status_color = (0, 165, 255)

        cv2.putText(frame, status, (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, status_color, 2)

        if len(faces) > 0 and can_capture:
            for (x, y, w, h) in faces:
                count += 1

                face_rgb = frame[y:y + h, x:x + w]
                filename = f"{folder_name}/User.{face_id}.{count}.jpg"
                cv2.imwrite(filename, face_rgb)

                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
                cv2.putText(frame, f"OK {count}", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

                print(f"\râœ… {count}/{max_images}", end="")

                last_capture_time = current_time

                if count >= max_images:
                    break
                break
        else:
            for (x, y, w, h) in faces:
                color = (0, 165, 255) if not can_capture else (255, 255, 0)
                cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)

        cv2.imshow(f'Camera {cam_type}', frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    detector.close()
    cap.release()
    cv2.destroyAllWindows()
    print(f"\n\nâœ… {count} áº£nh â†’ {folder_name}")
    input()

# TRAINING FACENET (TOÃ€N Bá»˜)

def train_model():
    print_header()
    print("     TRAINING FACENET (TOÃ€N Bá»˜)           ")

    if not os.path.exists("Mauanh"):
        print("âŒ ChÆ°a cÃ³ áº£nh!")
        input()
        return

    print("ğŸ“‚ Äá»c áº£nh tá»« cÃ¡c thÆ° má»¥c...")
    print("â±ï¸  Má»—i áº£nh ~40ms, vui lÃ²ng Ä‘á»£i...\n")

    embeddings_dict = {}
    total_images = 0
    start_time = time.time()

    # Äáº¿m tá»•ng sá»‘ áº£nh
    for folder_name in os.listdir("Mauanh"):
        folder_path = os.path.join("Mauanh", folder_name)
        if os.path.isdir(folder_path):
            for filename in os.listdir(folder_path):
                if filename.startswith("User.") and filename.endswith(".jpg"):
                    total_images += 1
        elif folder_name.startswith("User.") and folder_name.endswith(".jpg"):
            total_images += 1

    if total_images == 0:
        print("âŒ KhÃ´ng cÃ³ áº£nh!")
        input()
        return

    print(f"ğŸ“Š TÃ¬m tháº¥y {total_images} áº£nh\n")

    processed = 0

    # Äá»c tá»« folders
    for folder_name in os.listdir("Mauanh"):
        folder_path = os.path.join("Mauanh", folder_name)

        if os.path.isdir(folder_path):
            for filename in os.listdir(folder_path):
                if filename.startswith("User.") and filename.endswith(".jpg"):
                    path = os.path.join(folder_path, filename)
                    user_id = int(filename.split(".")[1])

                    img = cv2.imread(path)
                    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                    embedding = get_embedding(img_rgb)

                    if embedding is not None:
                        if user_id not in embeddings_dict:
                            embeddings_dict[user_id] = []
                        embeddings_dict[user_id].append(embedding)

                    processed += 1
                    print(f"\rğŸ”„ Processing: {processed}/{total_images} ({processed * 100 // total_images}%)", end="")

        elif folder_name.startswith("User.") and folder_name.endswith(".jpg"):
            path = os.path.join("Mauanh", folder_name)
            user_id = int(folder_name.split(".")[1])

            img = cv2.imread(path)
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            embedding = get_embedding(img_rgb)

            if embedding is not None:
                if user_id not in embeddings_dict:
                    embeddings_dict[user_id] = []
                embeddings_dict[user_id].append(embedding)

            processed += 1
            print(f"\rğŸ”„ Processing: {processed}/{total_images} ({processed * 100 // total_images}%)", end="")

    print("\n\nğŸ“Š TÃ­nh embeddings trung bÃ¬nh cho má»—i user...")

    final_database = {}
    for user_id, embeddings in embeddings_dict.items():
        mean_embedding = np.mean(embeddings, axis=0)
        mean_embedding = mean_embedding / np.linalg.norm(mean_embedding)
        final_database[user_id] = mean_embedding
        print(f"   User {user_id}: {len(embeddings)} áº£nh â†’ 1 embedding (512-dim)")

    if not os.path.exists("trainer"):
        os.makedirs("trainer")

    np.save("trainer/facenet_database.npy", np.array(final_database, dtype=object))

    elapsed = time.time() - start_time
    print(f"\nâœ… Xong! File: trainer/facenet_database.npy")
    print(f"â±ï¸  Thá»i gian: {elapsed:.1f}s")
    print(f"ğŸ“Š {len(final_database)} users, {total_images} áº£nh")
    input("\nEnter...")

# TRAINING FACENET

def train_model_incremental():
    print_header()
    print("TRAINING NGÆ¯á»œI Má»šI (INCREMENTAL)     ")

    if not os.path.exists("trainer/facenet_database.npy"):
        print(" ChÆ°a cÃ³ database cÅ©!")
        print(" DÃ¹ng [2] Ä‘á»ƒ train toÃ n bá»™ láº§n Ä‘áº§u")
        input()
        return

    # Load database cÅ©
    print("ğŸ“‚ Load database cÅ©...")
    old_database = np.load("trainer/facenet_database.npy", allow_pickle=True).item()
    print(f"âœ… Database cÅ©: {len(old_database)} users")

    # TÃ¬m táº¥t cáº£ user_ids trong Mauanh
    print("\n QuÃ©t thÆ° má»¥c Mauanh...")
    all_user_ids = set()

    for folder_name in os.listdir("Mauanh"):
        folder_path = os.path.join("Mauanh", folder_name)

        if os.path.isdir(folder_path):
            for filename in os.listdir(folder_path):
                if filename.startswith("User.") and filename.endswith(".jpg"):
                    user_id = int(filename.split(".")[1])
                    all_user_ids.add(user_id)

        elif folder_name.startswith("User.") and folder_name.endswith(".jpg"):
            user_id = int(folder_name.split(".")[1])
            all_user_ids.add(user_id)

    # TÃ¬m users má»›i (chÆ°a cÃ³ trong database)
    new_user_ids = all_user_ids - set(old_database.keys())

    if not new_user_ids:
        print("\nâœ… KhÃ´ng cÃ³ user má»›i!")
        print("ğŸ’¡ Táº¥t cáº£ users Ä‘Ã£ Ä‘Æ°á»£c train")
        input()
        return

    print(f"âœ… TÃ¬m tháº¥y {len(all_user_ids)} users trong Mauanh")
    print(f"ğŸ†• Users má»›i: {sorted(new_user_ids)}\n")

    # Train chá»‰ ngÆ°á»i má»›i
    embeddings_dict = {}
    total_new_images = 0

    # Äáº¿m áº£nh cá»§a ngÆ°á»i má»›i
    for folder_name in os.listdir("Mauanh"):
        folder_path = os.path.join("Mauanh", folder_name)

        if os.path.isdir(folder_path):
            for filename in os.listdir(folder_path):
                if filename.startswith("User.") and filename.endswith(".jpg"):
                    user_id = int(filename.split(".")[1])
                    if user_id in new_user_ids:
                        total_new_images += 1

        elif folder_name.startswith("User.") and folder_name.endswith(".jpg"):
            user_id = int(folder_name.split(".")[1])
            if user_id in new_user_ids:
                total_new_images += 1

    print(f"ğŸ“Š TÃ¬m tháº¥y {total_new_images} áº£nh cá»§a ngÆ°á»i má»›i\n")

    processed = 0
    start_time = time.time()

    # Process chá»‰ áº£nh cá»§a ngÆ°á»i má»›i
    for folder_name in os.listdir("Mauanh"):
        folder_path = os.path.join("Mauanh", folder_name)

        if os.path.isdir(folder_path):
            for filename in os.listdir(folder_path):
                if filename.startswith("User.") and filename.endswith(".jpg"):
                    user_id = int(filename.split(".")[1])

                    if user_id not in new_user_ids:
                        continue  # Skip ngÆ°á»i Ä‘Ã£ cÃ³

                    path = os.path.join(folder_path, filename)
                    img = cv2.imread(path)
                    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                    embedding = get_embedding(img_rgb)

                    if embedding is not None:
                        if user_id not in embeddings_dict:
                            embeddings_dict[user_id] = []
                        embeddings_dict[user_id].append(embedding)

                    processed += 1
                    print(f"\rğŸ”„ Processing: {processed}/{total_new_images} ({processed * 100 // total_new_images}%)", end="")

        elif folder_name.startswith("User.") and folder_name.endswith(".jpg"):
            user_id = int(folder_name.split(".")[1])

            if user_id not in new_user_ids:
                continue  # Skip ngÆ°á»i Ä‘Ã£ cÃ³

            path = os.path.join("Mauanh", folder_name)
            img = cv2.imread(path)
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            embedding = get_embedding(img_rgb)

            if embedding is not None:
                if user_id not in embeddings_dict:
                    embeddings_dict[user_id] = []
                embeddings_dict[user_id].append(embedding)

            processed += 1
            print(f"\rğŸ”„ Processing: {processed}/{total_new_images} ({processed * 100 // total_new_images}%)", end="")

    print("\n\nğŸ“Š TÃ­nh embeddings cho ngÆ°á»i má»›i...")

    # TÃ­nh mean embedding cho ngÆ°á»i má»›i
    new_embeddings = {}
    for user_id, embeddings in embeddings_dict.items():
        mean_embedding = np.mean(embeddings, axis=0)
        mean_embedding = mean_embedding / np.linalg.norm(mean_embedding)
        new_embeddings[user_id] = mean_embedding
        print(f"   User {user_id}: {len(embeddings)} áº£nh â†’ 1 embedding")

    # Merge vá»›i database cÅ©
    final_database = {**old_database, **new_embeddings}

    # Save
    np.save("trainer/facenet_database.npy", np.array(final_database, dtype=object))

    elapsed = time.time() - start_time
    print(f"\nâœ… Xong! File: trainer/facenet_database.npy")
    print(f"â±ï¸  Thá»i gian: {elapsed:.1f}s")
    print(f"ğŸ“Š Database: {len(old_database)} cÅ© + {len(new_embeddings)} má»›i = {len(final_database)} total")
    print(f"\nğŸ’¡ Tiáº¿t kiá»‡m: Chá»‰ train {total_new_images} áº£nh thay vÃ¬ toÃ n bá»™!")
    input("\nEnter...")

# RECOGNITION (FACENET)


def recognition_dual_camera():
    print_header()
    print("        NHáº¬N DIá»†N (FaceNet)                  ")


    if not os.path.exists("trainer/facenet_database.npy"):
        print("âŒ ChÆ°a train! Chá»n [2] hoáº·c [3]")
        input()
        return

    print("ğŸ”„ Load FaceNet database...")
    database = np.load("trainer/facenet_database.npy", allow_pickle=True).item()
    print(f"âœ… Loaded {len(database)} users")

    users = load_users_from_google_sheets()

    if not users:
        users = {}
        for user_id in database.keys():
            users[user_id] = {'name': f'User {user_id}', 'rfid': ''}

    print(f"âœ… {len(users)} ngÆ°á»i")
    print(f"ğŸ¯ MediaPipe + FaceNet")
    print(f"ğŸ¯ Threshold: {FACENET_THRESHOLD}")
    print("ğŸŸ¢ START - Q thoÃ¡t\n")

    stop_event = threading.Event()

    def camera_thread(cam_url, cam_type, is_checkout):
        cap = cv2.VideoCapture(cam_url)
        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)

        if not cap.isOpened():
            print(f"âŒ Camera {cam_type} lá»—i!")
            return

        detector = mp_face_detection.FaceDetection(model_selection=0,
                                                   min_detection_confidence=MEDIAPIPE_CONFIDENCE)  # type: ignore
        last_id, last_time, count = -1, 0, 0
        fps, fc, lt = 0, 0, time.time()

        color = (0, 255, 255) if is_checkout else (0, 255, 0)

        while not stop_event.is_set():
            ret, frame = cap.read()
            if not ret:
                time.sleep(0.01)
                continue

            fc += 1
            ct = time.time()
            if ct - lt >= 1.0:
                fps, fc, lt = fc, 0, ct

            faces = detect_faces(frame, detector)

            if len(faces) == 0:
                status_text = "No face detected"
                status_color = (128, 128, 128)
                cv2.putText(frame, status_text, (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, status_color, 2)
            else:
                for (x, y, w, h) in faces:
                    time_since_last = ct - last_time
                    in_cooldown = (last_id != -1 and time_since_last <= COOLDOWN_SECONDS)

                    if in_cooldown:
                        name = users[last_id]['name'] if last_id in users else "Unknown"
                        cooldown_remaining = COOLDOWN_SECONDS - time_since_last
                        col = (0, 255, 0)
                        conf_text = f"{cooldown_remaining:.0f}s"

                        cv2.rectangle(frame, (x, y), (x + w, y + h), col, 2)
                        cv2.putText(frame, f"{name} ({conf_text})", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, col, 2)
                        continue

                    face_bgr = frame[y:y + h, x:x + w]
                    face_rgb = cv2.cvtColor(face_bgr, cv2.COLOR_BGR2RGB)

                    embedding = get_embedding(face_rgb)

                    if embedding is None:
                        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 165, 255), 2)
                        cv2.putText(frame, "Processing...", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 165, 255), 2)
                        continue

                    min_distance = float('inf')
                    predicted_id = -1

                    for user_id, db_embedding in database.items():
                        distance = compare_embeddings(embedding, db_embedding)
                        if distance < min_distance:
                            min_distance = distance
                            predicted_id = user_id

                    if min_distance < FACENET_THRESHOLD and predicted_id in users:
                        name = users[predicted_id]['name']
                        conf_text = f"{(1 - min_distance) * 100:.0f}%"

                        send_face_to_blynk(predicted_id, name, is_checkout)
                        last_id, last_time, count = predicted_id, ct, count + 1
                        col = (0, 255, 0)
                    else:
                        name = "Unknown"
                        col = (0, 0, 255)
                        conf_text = f"{(1 - min_distance) * 100:.0f}%" if min_distance < 1 else "0%"

                    cv2.rectangle(frame, (x, y), (x + w, y + h), col, 2)
                    cv2.putText(frame, f"{name} ({conf_text})", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, col, 2)

            cv2.putText(frame, f"{cam_type}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
            cv2.putText(frame, f"FPS: {fps}", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
            cv2.imshow(f'Camera {cam_type}', frame)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                stop_event.set()

        detector.close()
        cap.release()

    t1 = threading.Thread(target=camera_thread, args=(ESP32CAM_IN, "IN", False))
    t2 = threading.Thread(target=camera_thread, args=(ESP32CAM_OUT, "OUT", True))

    t1.start()
    t2.start()
    t1.join()
    t2.join()

    cv2.destroyAllWindows()
    print("\nğŸ”´ Táº¯t")
    input()

# MANAGE

def manage_users():
    print_header()
    print(" QUáº¢N LÃ                  ")


    users = load_users_from_google_sheets()
    if not users:
        print("âŒ KhÃ´ng load Ä‘Æ°á»£c!")
        input()
        return

    print("ğŸ“‹ DANH SÃCH:\n")
    print(f"{'ID':<5} {'TÃªn':<25} {'RFID':<15} {'áº¢nh':<10}")
    print("-" * 60)

    for uid, info in users.items():
        folder_name = f"Mauanh/{info['name'].replace(' ', '_')}"
        ic = 0

        if os.path.exists(folder_name) and os.path.isdir(folder_name):
            ic = len([fn for fn in os.listdir(folder_name) if fn.startswith(f"User.{uid}.")])

        if os.path.exists("Mauanh"):
            ic += len([fn for fn in os.listdir("Mauanh")
                       if fn.startswith(f"User.{uid}.") and os.path.isfile(os.path.join("Mauanh", fn))])

        print(f"{uid:<5} {info['name']:<25} {info['rfid']:<15} {ic} áº£nh")

    print("\n1. Xem áº£nh | 2. XÃ³a | 0. Quay láº¡i")
    choice = input("\nChá»n: ").strip()

    if choice == '1':
        try:
            uid = int(input("\nID: ").strip())
            if uid in users:
                imgs = []
                folder_name = f"Mauanh/{users[uid]['name'].replace(' ', '_')}"

                if os.path.exists(folder_name) and os.path.isdir(folder_name):
                    imgs += [os.path.join(folder_name, fn) for fn in os.listdir(folder_name)
                             if fn.startswith(f"User.{uid}.")]

                if os.path.exists("Mauanh"):
                    imgs += [os.path.join("Mauanh", fn) for fn in os.listdir("Mauanh")
                             if fn.startswith(f"User.{uid}.") and os.path.isfile(os.path.join("Mauanh", fn))]

                if imgs:
                    idx = 0
                    while True:
                        img = cv2.imread(imgs[idx])
                        if img is not None:
                            img = cv2.resize(img, (400, 400))
                            cv2.putText(img, f"{users[uid]['name']} ({idx + 1}/{len(imgs)})",
                                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                            cv2.imshow('Images', img)
                        key = cv2.waitKey(0) & 0xFF
                        if key == ord('q'):
                            break
                        elif key == ord(' '):
                            idx = (idx + 1) % len(imgs)
                    cv2.destroyAllWindows()
        except:
            pass
        input()

    elif choice == '2':
        try:
            uid = int(input("\nID xÃ³a: ").strip())
            if uid in users and input(f"XÃ³a '{users[uid]['name']}'? (yes/no): ").lower() == 'yes':
                dc = 0
                folder_name = f"Mauanh/{users[uid]['name'].replace(' ', '_')}"

                if os.path.exists(folder_name) and os.path.isdir(folder_name):
                    import shutil
                    shutil.rmtree(folder_name)
                    print(f"âœ… XÃ³a folder: {folder_name}")

                if os.path.exists("Mauanh"):
                    for fn in os.listdir("Mauanh"):
                        if fn.startswith(f"User.{uid}.") and os.path.isfile(os.path.join("Mauanh", fn)):
                            os.remove(os.path.join("Mauanh", fn))
                            dc += 1

                print(f"âœ… XÃ³a {dc} áº£nh. Train láº¡i!")
        except:
            pass
        input()

# MAIN
def main():
    while True:
        print_menu()
        choice = input("\nChá»n: ").strip()
        if choice == '1':
            collect_faces()
        elif choice == '2':
            train_model()
        elif choice == '3':
            train_model_incremental()
        elif choice == '4':
            recognition_dual_camera()
        elif choice == '5':
            manage_users()
        elif choice == '0':
            print("\nğŸ‘‹ Bye!")
            break


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nâš ï¸ Stop!")
    finally:
        cv2.destroyAllWindows()